{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sparse_vector'...\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n",
      "Cloning into 'z_dna'...\n",
      "remote: Enumerating objects: 2052, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 2052 (delta 8), reused 0 (delta 0), pack-reused 2021\u001b[K\n",
      "Receiving objects: 100% (2052/2052), 1.75 GiB | 10.06 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "Checking out files: 100% (2024/2024), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Sparse_vector\n",
    "!git clone https://github.com/vladislareon/z_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Interpretation'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 37 (delta 14), reused 2 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (37/37), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "#import Sparse_vector\n",
    "#sys.modules['sparse_vector'] = Sparse_vector\n",
    "from Sparse_vector.sparse_vector import SparseVector\n",
    "from Interpretation.lrp_layers import LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "all_features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features]\n",
    "\n",
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cb5121f4cf42cca5f0d5cfa16fa7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e011cea7004f26927328b3cd9c3dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 5.7 s, total: 1min 31s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chroms)}\n",
    "# ZDNA_shin = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "# ZDNA_cousine = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms, features, \n",
    "                 dna_source, features_source, \n",
    "                 labels_source, intervals):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "        \n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        \n",
    "        return (X, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 2489564/2489564 [00:35<00:00, 69540.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 2421935/2421935 [00:33<00:00, 72082.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:27<00:00, 71829.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:26<00:00, 72358.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:25<00:00, 71032.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:23<00:00, 71811.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:20<00:00, 76325.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:20<00:00, 70444.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:18<00:00, 74095.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:17<00:00, 75659.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:19<00:00, 68495.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:18<00:00, 74014.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:15<00:00, 73980.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:14<00:00, 74727.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:15<00:00, 65473.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 903383/903383 [00:11<00:00, 76755.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 832574/832574 [00:10<00:00, 77267.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 803732/803732 [00:10<00:00, 77035.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 586176/586176 [00:07<00:00, 74484.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 644441/644441 [00:08<00:00, 73754.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 467099/467099 [00:06<00:00, 73886.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 508184/508184 [00:06<00:00, 75146.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:23<00:00, 66973.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 572274/572274 [00:07<00:00, 75118.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 55802.30it/s]\n"
     ]
    }
   ],
   "source": [
    "width = 100\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 3, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = ints_in\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
    "                                                                 for i, elem \n",
    "                                                                 in enumerate(equalized)]))\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "train_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size':1,\n",
    "          'num_workers':20,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DeepCNNLayerNorm_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([3, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(3, 5, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([5, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(5, 7, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([7, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(7, 9, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([9, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(9, 11, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([11, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(11, 13, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([13, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(13, 13, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(13, 11, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([11, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(11, 9, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([9, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(9, 7, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([7, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(7, 5, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([5, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(5, 3, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([3, 100, 1950]),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(3, 1, kernel_size=(3, 3), padding=1),\n",
    "            nn.LayerNorm([1, 100, 1950]),  # Укажите размеры после свертки\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(1950, 500),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(500, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.reshape(batch, 1, width, 1950)\n",
    "        x = self.seq(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCNNLayerNorm_v2(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LayerNorm((3, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LayerNorm((5, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LayerNorm((7, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(7, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): LayerNorm((9, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): LayerNorm((11, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(11, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): LayerNorm((13, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): Conv2d(13, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): LayerNorm((11, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (22): ReLU()\n",
       "    (23): Conv2d(11, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): LayerNorm((9, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (25): ReLU()\n",
       "    (26): Conv2d(9, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): LayerNorm((7, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (28): ReLU()\n",
       "    (29): Conv2d(7, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (30): LayerNorm((5, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (31): ReLU()\n",
       "    (32): Conv2d(5, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): LayerNorm((3, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (34): ReLU()\n",
       "    (35): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (36): LayerNorm((1, 100, 1950), eps=1e-05, elementwise_affine=True)\n",
       "    (37): ReLU()\n",
       "    (38): Dropout(p=0.25, inplace=False)\n",
       "    (39): Linear(in_features=1950, out_features=500, bias=True)\n",
       "    (40): Dropout(p=0.25, inplace=False)\n",
       "    (41): ReLU()\n",
       "    (42): Linear(in_features=500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepCNNLayerNorm_v2()\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load(\"Cousine_DeepCNNLayerNorm_v2_interval=100_F1=0.759_epoch=20.pt\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP, InputXGradient, GuidedBackprop, Deconvolution\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23740b60c2f64889af0cc721843b16e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d2033bc9464091a7db2c7d37cb77f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done IntegratedGradients interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_ig1 = np.zeros(1950, dtype=float)\n",
    "cnt_ig = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # IntegratedGradients\n",
    "    #torch.cuda.empty_cache()\n",
    "    integrated_gradients = IntegratedGradients(model).attribute(x, target=1, n_steps=1)\n",
    "    integrated_gradients = torch.squeeze(integrated_gradients, dim=0)\n",
    "    \n",
    "    if integrated_gradients[idxs, :].shape != (0, 1950):\n",
    "        integrated_gradients = torch.mean(integrated_gradients[idxs, :], dim=0)\n",
    "        integrated_gradients = np.array(integrated_gradients.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ig1 += integrated_gradients\n",
    "        cnt_ig += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # IntegratedGradients\n",
    "    #torch.cuda.empty_cache()\n",
    "    integrated_gradients = IntegratedGradients(model).attribute(x, target=1, n_steps=1)\n",
    "    integrated_gradients = torch.squeeze(integrated_gradients, dim=0)\n",
    "    \n",
    "    if integrated_gradients[idxs, :].shape != (0, 1950):\n",
    "        integrated_gradients = torch.mean(integrated_gradients[idxs, :], dim=0)\n",
    "        integrated_gradients = np.array(integrated_gradients.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ig1 += integrated_gradients\n",
    "        cnt_ig += 1\n",
    "\n",
    "print('done IntegratedGradients interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.45094543e+00  1.66814336e+01  1.60696188e+01 ...  0.00000000e+00\n",
      "  1.12107443e-04  2.45436798e-06]\n"
     ]
    }
   ],
   "source": [
    "# mean for IntegratedGradients\n",
    "mean_ig = mean_ig1 / cnt_ig\n",
    "print(mean_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_ig_CNN_075.npy', mean_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4f92eeefbc427b95db216e0ca07ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b59fd768c64017807f0383ebcf1ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done InputXGradient interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_ixg1 = np.zeros(1950, dtype=float)\n",
    "cnt_ixg = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # InputXGradient\n",
    "    inputx_gradients = InputXGradient(model).attribute(x, target=1)\n",
    "    inputx_gradients = torch.squeeze(inputx_gradients, dim=0)\n",
    "    \n",
    "    if inputx_gradients[idxs, :].shape != (0, 1950):\n",
    "        inputx_gradients = torch.mean(inputx_gradients[idxs, :], dim=0)\n",
    "        inputx_gradients = inputx_gradients.cpu().detach().numpy()\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ixg1 += inputx_gradients\n",
    "        cnt_ixg += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # InputXGradient\n",
    "    inputx_gradients = InputXGradient(model).attribute(x, target=1)\n",
    "    inputx_gradients = torch.squeeze(inputx_gradients, dim=0)\n",
    "    \n",
    "    if inputx_gradients[idxs, :].shape != (0, 1950):\n",
    "        inputx_gradients = torch.mean(inputx_gradients[idxs, :], dim=0)\n",
    "        inputx_gradients = inputx_gradients.cpu().detach().numpy()\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ixg1 += inputx_gradients\n",
    "        cnt_ixg += 1\n",
    "\n",
    "print('done InputXGradient interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.51535648e-01  1.08634184e+01  7.69323746e+00 ...  0.00000000e+00\n",
      "  1.45848921e-05 -5.00266947e-08]\n"
     ]
    }
   ],
   "source": [
    "# mean for InputXGradient\n",
    "mean_ixg = mean_ixg1 / cnt_ixg\n",
    "print(mean_ixg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_input_x_gradient_CNN_075.npy', mean_ixg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f395645d094d90a25638940776bcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239d4c31f2b24975bb51b90be92066dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done GuidedBackprop interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_gbp1 = np.zeros(1950, dtype=float)\n",
    "cnt_gbp = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedBackprop\n",
    "\n",
    "    gbp = GuidedBackprop(model).attribute(x, target=1)\n",
    "    gbp = torch.squeeze(gbp, dim=0)\n",
    "    \n",
    "    if gbp[idxs, :].shape != (0, 1950):\n",
    "        gbp = torch.mean(gbp[idxs, :], dim=0)\n",
    "        gbp = np.array(gbp.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_gbp1 += gbp\n",
    "        cnt_gbp += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedBackprop\n",
    "\n",
    "    gbp = GuidedBackprop(model).attribute(x, target=1)\n",
    "    gbp = torch.squeeze(gbp, dim=0)\n",
    "    \n",
    "    if gbp[idxs, :].shape != (0, 1950):\n",
    "        gbp = torch.mean(gbp[idxs, :], dim=0)\n",
    "        gbp = np.array(gbp.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_gbp1 += gbp\n",
    "        cnt_gbp += 1\n",
    "\n",
    "print('done GuidedBackprop interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.38537559e-01  1.33175356e+00  2.05166828e+00 ... -9.81499988e-04\n",
      " -9.51754645e-04 -8.76049912e-04]\n"
     ]
    }
   ],
   "source": [
    "# mean for GuidedBackprop\n",
    "mean_gbp = mean_gbp1 / cnt_gbp\n",
    "print(mean_gbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_guided_backprop_CNN_075.npy', mean_gbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0daf49f8714e71835494da060ec4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c2b755640b462a9f80700a315f037d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Deconvolution interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_dec1 = np.zeros(1950, dtype=float)\n",
    "cnt_dec = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # Deconvolution\n",
    "\n",
    "    dec = Deconvolution(model).attribute(x, target=1)\n",
    "    dec = torch.squeeze(dec, dim=0)\n",
    "    \n",
    "    if dec[idxs, :].shape != (0, 1950):\n",
    "        dec = torch.mean(dec[idxs, :], dim=0)\n",
    "        dec = np.array(dec.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_dec1 += dec\n",
    "        cnt_dec += 1\n",
    "\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # Deconvolution\n",
    "\n",
    "    dec = Deconvolution(model).attribute(x, target=1)\n",
    "    dec = torch.squeeze(dec, dim=0)\n",
    "    \n",
    "    if dec[idxs, :].shape != (0, 1950):\n",
    "        dec = torch.mean(dec[idxs, :], dim=0)\n",
    "        dec = np.array(dec.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_dec1 += dec\n",
    "        cnt_dec += 1\n",
    "\n",
    "print('done Deconvolution interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.50489990e+00  5.78859345e+00  8.06691777e+00 ... -8.18742583e-03\n",
      " -7.97827533e-03 -7.27760765e-03]\n"
     ]
    }
   ],
   "source": [
    "# mean for Deconvolution\n",
    "mean_dec = mean_dec1 / cnt_dec\n",
    "print(mean_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_deconv_CNN_075.npy', mean_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerGradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d2e7c4cca41d5adf65e5827a57bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d9ed3a79da4117a6535b4354d08fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done LayerGradCam interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_gcam1 = np.zeros(1950, dtype=float)\n",
    "cnt_gcam = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedGradCam\n",
    "    \n",
    "    layers = list(model.modules())[2:]\n",
    "    #layers[5] = Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    grad_cam = LayerGradCam(model, layer=layers[5]).attribute(x, target=1)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    \n",
    "    if grad_cam[idxs, :].shape != (0, 1950):\n",
    "        grad_cam = torch.mean(grad_cam[idxs, :], dim=0)\n",
    "        grad_cam = grad_cam.cpu().detach().numpy()\n",
    "        mean_gcam1 += grad_cam\n",
    "        cnt_gcam += 1\n",
    "\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedGradCam\n",
    "    \n",
    "    layers = list(model.modules())[2:]\n",
    "    #layers[5] = Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    grad_cam = LayerGradCam(model, layer=layers[5]).attribute(x, target=1)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    \n",
    "    if grad_cam[idxs, :].shape != (0, 1950):\n",
    "        grad_cam = torch.mean(grad_cam[idxs, :], dim=0)\n",
    "        grad_cam = grad_cam.cpu().detach().numpy()\n",
    "        mean_gcam1 += grad_cam\n",
    "        cnt_gcam += 1\n",
    "\n",
    "\n",
    "print('done LayerGradCam interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n",
      "[-0.00132167 -0.00194491 -0.00131476 ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# mean for LayerGradCam\n",
    "mean_gcam = mean_gcam1 / cnt_gcam\n",
    "print(mean_gcam.shape)\n",
    "print(mean_gcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_gcam_CNN_075.npy', mean_gcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
