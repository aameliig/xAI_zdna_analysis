{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sparse_vector'...\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n",
      "Cloning into 'z_dna'...\n",
      "remote: Enumerating objects: 2052, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 2052 (delta 8), reused 0 (delta 0), pack-reused 2021\u001b[K\n",
      "Receiving objects: 100% (2052/2052), 1.75 GiB | 10.06 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "Checking out files: 100% (2024/2024), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Sparse_vector\n",
    "!git clone https://github.com/vladislareon/z_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Interpretation'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 37 (delta 14), reused 2 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (37/37), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "#import Sparse_vector\n",
    "#sys.modules['sparse_vector'] = Sparse_vector\n",
    "from Sparse_vector.sparse_vector import SparseVector\n",
    "from Interpretation.lrp_layers import LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "all_features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features]\n",
    "\n",
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97d4c1d835340268f19b1056af4d46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab13f8228926403abaf2a5994cbed76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 7.48 s, total: 2min 55s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chroms)}\n",
    "# ZDNA_shin = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "# ZDNA_cousine = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms, features, \n",
    "                 dna_source, features_source, \n",
    "                 labels_source, intervals):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "        \n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        \n",
    "        return (X, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2489564/2489564 [01:10<00:00, 35367.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421935/2421935 [01:08<00:00, 35178.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:55<00:00, 35519.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:51<00:00, 37165.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:52<00:00, 34506.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:46<00:00, 36347.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:42<00:00, 37224.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:41<00:00, 35282.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:37<00:00, 36492.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:37<00:00, 35522.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:39<00:00, 33992.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:36<00:00, 36173.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:32<00:00, 35452.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:29<00:00, 36737.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:30<00:00, 33148.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 903383/903383 [00:24<00:00, 37149.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 832574/832574 [00:22<00:00, 36223.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 803732/803732 [00:22<00:00, 35718.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 586176/586176 [00:16<00:00, 35897.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 644441/644441 [00:17<00:00, 36666.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 467099/467099 [00:12<00:00, 36387.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 508184/508184 [00:14<00:00, 35091.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:45<00:00, 34057.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 572274/572274 [00:15<00:00, 36021.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 29339.50it/s]\n"
     ]
    }
   ],
   "source": [
    "width = 100\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 3, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = ints_in\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
    "                                                                 for i, elem \n",
    "                                                                 in enumerate(equalized)]))\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "train_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size':1,\n",
    "          'num_workers':20,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DeepCNN_12_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(2, 4),\n",
    "\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 8),\n",
    " \n",
    "\n",
    "            nn.Conv2d(8, 16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, 16),\n",
    "\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 32),\n",
    "\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 64), \n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 5), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(32, 128),  \n",
    "\n",
    "\n",
    "            nn.Conv2d(128, 64, kernel_size=(3, 3), padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(32, 64),  \n",
    "\n",
    "\n",
    "            \n",
    "            nn.Conv2d(64, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(16, 32),  \n",
    "\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(8, 16), \n",
    "\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=(3, 3), padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 8),  \n",
    "\n",
    "\n",
    "            nn.Conv2d(8, 4, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(4, 4),  \n",
    "\n",
    "\n",
    "            nn.Conv2d(4, 1, kernel_size=(3, 3), padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.GroupNorm(1, 1), \n",
    "\n",
    "\n",
    "            \n",
    "            nn.AlphaDropout(p = 0.2),\n",
    "            nn.Linear(1950, 500),\n",
    "            nn.AlphaDropout(p = 0.2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(500, 2)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.reshape(batch, 1, width, 1950)\n",
    "        x = self.seq(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCNN_12_layers(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): GroupNorm(2, 4, eps=1e-05, affine=True)\n",
       "    (3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): GroupNorm(4, 8, eps=1e-05, affine=True)\n",
       "    (6): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "    (9): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): GroupNorm(16, 32, eps=1e-05, affine=True)\n",
       "    (12): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "    (15): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (16): ReLU()\n",
       "    (17): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "    (18): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (21): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU()\n",
       "    (23): GroupNorm(16, 32, eps=1e-05, affine=True)\n",
       "    (24): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU()\n",
       "    (26): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "    (27): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): ReLU()\n",
       "    (29): GroupNorm(4, 8, eps=1e-05, affine=True)\n",
       "    (30): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU()\n",
       "    (32): GroupNorm(4, 4, eps=1e-05, affine=True)\n",
       "    (33): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): ReLU()\n",
       "    (35): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "    (36): AlphaDropout(p=0.2, inplace=False)\n",
       "    (37): Linear(in_features=1950, out_features=500, bias=True)\n",
       "    (38): AlphaDropout(p=0.2, inplace=False)\n",
       "    (39): SELU()\n",
       "    (40): Linear(in_features=500, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepCNN_12_layers()\n",
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load(\"CNN_F_score_88.pt\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP, InputXGradient, GuidedBackprop, Deconvolution\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9425ffba5ea54e859d197a2d20f3e2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab5313f566c4c44a69f82e5f6dba9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done IntegratedGradients interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_ig1 = np.zeros(1950, dtype=float)\n",
    "cnt_ig = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # IntegratedGradients\n",
    "    #torch.cuda.empty_cache()\n",
    "    integrated_gradients = IntegratedGradients(model).attribute(x, target=1, n_steps=1)\n",
    "    integrated_gradients = torch.squeeze(integrated_gradients, dim=0)\n",
    "    \n",
    "    if integrated_gradients[idxs, :].shape != (0, 1950):\n",
    "        integrated_gradients = torch.mean(integrated_gradients[idxs, :], dim=0)\n",
    "        integrated_gradients = np.array(integrated_gradients.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ig1 += integrated_gradients\n",
    "        cnt_ig += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # IntegratedGradients\n",
    "    #torch.cuda.empty_cache()\n",
    "    integrated_gradients = IntegratedGradients(model).attribute(x, target=1, n_steps=1)\n",
    "    integrated_gradients = torch.squeeze(integrated_gradients, dim=0)\n",
    "    \n",
    "    if integrated_gradients[idxs, :].shape != (0, 1950):\n",
    "        integrated_gradients = torch.mean(integrated_gradients[idxs, :], dim=0)\n",
    "        integrated_gradients = np.array(integrated_gradients.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ig1 += integrated_gradients\n",
    "        cnt_ig += 1\n",
    "\n",
    "print('done IntegratedGradients interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.26967886e+00  1.64290855e+01  8.00062130e+00 ...  0.00000000e+00\n",
      "  4.36509200e-05  7.63198797e-06]\n"
     ]
    }
   ],
   "source": [
    "# mean for IntegratedGradients\n",
    "mean_ig = mean_ig1 / cnt_ig\n",
    "print(mean_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_ig_CNN_088.npy', mean_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a110d2fa7fb34d0f8112554a5ebd1a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamelia/python3.11-env/lib/python3.11/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94be4413ccd74a2aafd7f87d2b08c597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done InputXGradient interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_ixg1 = np.zeros(1950, dtype=float)\n",
    "cnt_ixg = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # InputXGradient\n",
    "    inputx_gradients = InputXGradient(model).attribute(x, target=1)\n",
    "    inputx_gradients = torch.squeeze(inputx_gradients, dim=0)\n",
    "    \n",
    "    if inputx_gradients[idxs, :].shape != (0, 1950):\n",
    "        inputx_gradients = torch.mean(inputx_gradients[idxs, :], dim=0)\n",
    "        inputx_gradients = inputx_gradients.cpu().detach().numpy()\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ixg1 += inputx_gradients\n",
    "        cnt_ixg += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # InputXGradient\n",
    "    inputx_gradients = InputXGradient(model).attribute(x, target=1)\n",
    "    inputx_gradients = torch.squeeze(inputx_gradients, dim=0)\n",
    "    \n",
    "    if inputx_gradients[idxs, :].shape != (0, 1950):\n",
    "        inputx_gradients = torch.mean(inputx_gradients[idxs, :], dim=0)\n",
    "        inputx_gradients = inputx_gradients.cpu().detach().numpy()\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_ixg1 += inputx_gradients\n",
    "        cnt_ixg += 1\n",
    "\n",
    "print('done InputXGradient interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.12471419e+00  4.76724273e+00  1.59675111e+00 ...  0.00000000e+00\n",
      " -4.40484185e-04  1.28100173e-06]\n"
     ]
    }
   ],
   "source": [
    "# mean for InputXGradient\n",
    "mean_ixg = mean_ixg1 / cnt_ixg\n",
    "print(mean_ixg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_input_x_gradient_CNN_088.npy', mean_ixg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3f7d07f91a43e2a9443b6dd0568e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamelia/python3.11-env/lib/python3.11/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:64: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034bae6636194922a65f4fa471ed2e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done GuidedBackprop interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_gbp1 = np.zeros(1950, dtype=float)\n",
    "cnt_gbp = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedBackprop\n",
    "\n",
    "    gbp = GuidedBackprop(model).attribute(x, target=1)\n",
    "    gbp = torch.squeeze(gbp, dim=0)\n",
    "    \n",
    "    if gbp[idxs, :].shape != (0, 1950):\n",
    "        gbp = torch.mean(gbp[idxs, :], dim=0)\n",
    "        gbp = np.array(gbp.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_gbp1 += gbp\n",
    "        cnt_gbp += 1\n",
    "\n",
    "\n",
    "# for test data\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedBackprop\n",
    "\n",
    "    gbp = GuidedBackprop(model).attribute(x, target=1)\n",
    "    gbp = torch.squeeze(gbp, dim=0)\n",
    "    \n",
    "    if gbp[idxs, :].shape != (0, 1950):\n",
    "        gbp = torch.mean(gbp[idxs, :], dim=0)\n",
    "        gbp = np.array(gbp.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_gbp1 += gbp\n",
    "        cnt_gbp += 1\n",
    "\n",
    "print('done GuidedBackprop interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.71225634  0.59871119  0.59361523 ... -0.00120023 -0.0178224\n",
      "  0.02949687]\n"
     ]
    }
   ],
   "source": [
    "# mean for GuidedBackprop\n",
    "mean_gbp = mean_gbp1 / cnt_gbp\n",
    "print(mean_gbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_guided_backprop_CNN_088.npy', mean_gbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701d0418655b46d4ae17f302308593b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf5dcdc501a43359caed7f21c6195b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Deconvolution interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_dec1 = np.zeros(1950, dtype=float)\n",
    "cnt_dec = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # Deconvolution\n",
    "\n",
    "    dec = Deconvolution(model).attribute(x, target=1)\n",
    "    dec = torch.squeeze(dec, dim=0)\n",
    "    \n",
    "    if dec[idxs, :].shape != (0, 1950):\n",
    "        dec = torch.mean(dec[idxs, :], dim=0)\n",
    "        dec = np.array(dec.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_dec1 += dec\n",
    "        cnt_dec += 1\n",
    "\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # Deconvolution\n",
    "\n",
    "    dec = Deconvolution(model).attribute(x, target=1)\n",
    "    dec = torch.squeeze(dec, dim=0)\n",
    "    \n",
    "    if dec[idxs, :].shape != (0, 1950):\n",
    "        dec = torch.mean(dec[idxs, :], dim=0)\n",
    "        dec = np.array(dec.cpu())\n",
    "        #print(np.max(integrated_gradients))\n",
    "        mean_dec1 += dec\n",
    "        cnt_dec += 1\n",
    "\n",
    "print('done Deconvolution interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.49066988 61.72961317 71.44140186 ...  1.61707744 -1.97937409\n",
      "  5.08526523]\n"
     ]
    }
   ],
   "source": [
    "# mean for Deconvolution\n",
    "mean_dec = mean_dec1 / cnt_dec\n",
    "print(mean_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_deconv_CNN_088.npy', mean_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerGradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d2e7c4cca41d5adf65e5827a57bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d9ed3a79da4117a6535b4354d08fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done LayerGradCam interpretation\n"
     ]
    }
   ],
   "source": [
    "mean_gcam1 = np.zeros(1950, dtype=float)\n",
    "cnt_gcam = 0\n",
    "\n",
    "for x, y_true in tqdm(loader_train):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedGradCam\n",
    "    \n",
    "    layers = list(model.modules())[2:]\n",
    "    #layers[5] = Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    grad_cam = LayerGradCam(model, layer=layers[5]).attribute(x, target=1)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    \n",
    "    if grad_cam[idxs, :].shape != (0, 1950):\n",
    "        grad_cam = torch.mean(grad_cam[idxs, :], dim=0)\n",
    "        grad_cam = grad_cam.cpu().detach().numpy()\n",
    "        mean_gcam1 += grad_cam\n",
    "        cnt_gcam += 1\n",
    "\n",
    "for x, y_true in tqdm(loader_test):\n",
    "    # make prediction\n",
    "    x, y_true = x.to(device), y_true.to(device).long()\n",
    "    output = model(x)\n",
    "    pred = torch.argmax(output, dim=1).reshape(1, width)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y_true[0][i] and y_true[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    # GuidedGradCam\n",
    "    \n",
    "    layers = list(model.modules())[2:]\n",
    "    #layers[5] = Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    grad_cam = LayerGradCam(model, layer=layers[5]).attribute(x, target=1)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    grad_cam = torch.squeeze(grad_cam, dim=0)\n",
    "    \n",
    "    if grad_cam[idxs, :].shape != (0, 1950):\n",
    "        grad_cam = torch.mean(grad_cam[idxs, :], dim=0)\n",
    "        grad_cam = grad_cam.cpu().detach().numpy()\n",
    "        mean_gcam1 += grad_cam\n",
    "        cnt_gcam += 1\n",
    "\n",
    "\n",
    "print('done LayerGradCam interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n",
      "[-0.00132167 -0.00194491 -0.00131476 ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# mean for LayerGradCam\n",
    "mean_gcam = mean_gcam1 / cnt_gcam\n",
    "print(mean_gcam.shape)\n",
    "print(mean_gcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_gcam_CNN_075.npy', mean_gcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
