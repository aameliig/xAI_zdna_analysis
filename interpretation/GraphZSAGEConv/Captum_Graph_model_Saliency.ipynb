{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sparse_vector'...\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n",
      "Cloning into 'z_dna'...\n",
      "remote: Enumerating objects: 2052, done.\u001b[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 2052 (delta 8), reused 0 (delta 0), pack-reused 2021\u001b[K\n",
      "Receiving objects: 100% (2052/2052), 1.75 GiB | 10.06 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "Checking out files: 100% (2024/2024), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Sparse_vector\n",
    "!git clone https://github.com/vladislareon/z_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Interpretation'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 37 (delta 14), reused 2 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (37/37), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vladislareon/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from joblib import load\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Graph dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# GNN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv, GATv2Conv, SAGEConv\n",
    "\n",
    "\n",
    "# Sparse vector\n",
    "from Sparse_vector.sparse_vector import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "features = [i[:-4] for i in os.listdir('z_dna/hg38_features/sparse/') if i.endswith('.pkl')]\n",
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"z_dna/hg38_dna/{file}\") for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef26ceee74f74f50b2c076797005e582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9efc84e0e97443f8f87061d627a718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 4.29 s, total: 1min 39s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_shin.pkl')\n",
    "#ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "ZDNA = load('z_dna/hg38_zdna/sparse/ZDNA_cousine.pkl')\n",
    "\n",
    "DNA_features = {feature: load(f'z_dna/hg38_features/sparse/{feature}.pkl')\n",
    "                for feature in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, chroms, features,\n",
    "                 dna_source, features_source,\n",
    "                 labels, intervals,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels = labels\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "\n",
    "        self.ei = [[],[]]\n",
    "        for i in range(width-1):\n",
    "            self.ei[0].append(i)\n",
    "            self.ei[0].append(i+1)\n",
    "            self.ei[1].append(i+1)\n",
    "            self.ei[1].append(i)\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def get(self, idx):\n",
    "        interval = self.intervals[idx]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "\n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "\n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor(np.array(self.ei), dtype=torch.long)\n",
    "\n",
    "        y = self.labels[interval[0]][interval[1]: interval[2]]\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "        return Data(x=X.unsqueeze(0), edge_index=edge_index, y=y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 2489564/2489564 [00:37<00:00, 66527.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 2421935/2421935 [00:35<00:00, 68929.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1982955/1982955 [00:29<00:00, 67218.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1902145/1902145 [00:27<00:00, 68667.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1815382/1815382 [00:25<00:00, 71703.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1708059/1708059 [00:24<00:00, 70301.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1593459/1593459 [00:21<00:00, 74917.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1451386/1451386 [00:21<00:00, 67539.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1383947/1383947 [00:18<00:00, 73033.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1337974/1337974 [00:18<00:00, 74308.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1350866/1350866 [00:20<00:00, 65413.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1332753/1332753 [00:17<00:00, 74712.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1143643/1143643 [00:15<00:00, 74669.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1070437/1070437 [00:14<00:00, 72663.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1019911/1019911 [00:16<00:00, 63658.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 903383/903383 [00:12<00:00, 73378.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 832574/832574 [00:11<00:00, 74038.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 803732/803732 [00:10<00:00, 75309.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 586176/586176 [00:07<00:00, 74411.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 644441/644441 [00:08<00:00, 73567.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 467099/467099 [00:06<00:00, 73911.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 508184/508184 [00:07<00:00, 70564.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1560408/1560408 [00:25<00:00, 61502.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 572274/572274 [00:08<00:00, 69969.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 49993.51it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "for chrm in chrom_names:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "            ints_in.append([chrm, interval[0], interval[1]])\n",
    "        else:\n",
    "            ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), size=len(ints_in) * 2, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "equalized = ints_in\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "train_inds, test_inds = next(StratifiedKFold().split(equalized, [f\"{int(i < 400)}_{elem[0]}\"\n",
    "                                                                 for i, elem\n",
    "                                                                 in enumerate(equalized)]))\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                            DNA, DNA_features,\n",
    "                            ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = GraphDataset(chrom_names, feature_names,\n",
    "                           DNA, DNA_features,\n",
    "                           ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':1,\n",
    "          'num_workers':4,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = DataLoader(train_dataset, **params)\n",
    "loader_test = DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphZSAGEConv_v5_lin(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GraphZSAGEConv_v5_lin, self).__init__()\n",
    "        self.conv1 = SAGEConv(1950, 1800)\n",
    "        self.conv2 = SAGEConv(1800, 1650)\n",
    "        self.conv3 = SAGEConv(1650, 1500)\n",
    "        self.conv4 = SAGEConv(1500, 1350)\n",
    "        self.conv5 = SAGEConv(1350, 1200)\n",
    "        self.conv6 = SAGEConv(1200, 1050)\n",
    "        self.conv7 = SAGEConv(1050, 900)\n",
    "        self.conv8 = SAGEConv(900, 750)\n",
    "        self.conv9 = SAGEConv(750, 600)\n",
    "        self.conv10 = SAGEConv(600, 450)\n",
    "        self.conv11 = SAGEConv(450, 300)\n",
    "        self.conv12 = SAGEConv(300, 150)\n",
    "        self.conv13 = SAGEConv(150, 64)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(64, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x, edge):\n",
    "        x = self.conv1(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv4(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv5(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv6(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv7(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv8(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv9(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv10(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv11(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv12(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv13(x, edge)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphZSAGEConv_v5_lin(\n",
       "  (conv1): SAGEConv(1950, 1800, aggr=mean)\n",
       "  (conv2): SAGEConv(1800, 1650, aggr=mean)\n",
       "  (conv3): SAGEConv(1650, 1500, aggr=mean)\n",
       "  (conv4): SAGEConv(1500, 1350, aggr=mean)\n",
       "  (conv5): SAGEConv(1350, 1200, aggr=mean)\n",
       "  (conv6): SAGEConv(1200, 1050, aggr=mean)\n",
       "  (conv7): SAGEConv(1050, 900, aggr=mean)\n",
       "  (conv8): SAGEConv(900, 750, aggr=mean)\n",
       "  (conv9): SAGEConv(750, 600, aggr=mean)\n",
       "  (conv10): SAGEConv(600, 450, aggr=mean)\n",
       "  (conv11): SAGEConv(450, 300, aggr=mean)\n",
       "  (conv12): SAGEConv(300, 150, aggr=mean)\n",
       "  (conv13): SAGEConv(150, 64, aggr=mean)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GraphZSAGEConv_v5_lin()\n",
    "model.load_state_dict(torch.load(\"Cousine_GraphZSAGEConv_v5_lin_F1=77.75_epoch=17.pt\"))\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum methods: Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum\n",
    "from captum.attr import IntegratedGradients, GradientShap, LayerGradCam, LRP\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('Saliency'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c262d1a99d4f4fa38273db12abba1143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamelia/python3.11-env/lib/python3.11/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done interpretation\n",
      "CPU times: user 1h 1min 3s, sys: 18min 22s, total: 1h 19min 26s\n",
      "Wall time: 1h 19min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_1 = np.zeros(1950, dtype=float)\n",
    "cnt= 0\n",
    "\n",
    "for dt in tqdm(loader_test):\n",
    "    x, edge, y = dt.x.cuda(), dt.edge_index.cuda(), dt.y.cuda().long()\n",
    "    valid_edges = (edge < width).all(dim=0)\n",
    "    edge = edge[:, valid_edges]\n",
    "\n",
    "    output = model(x, edge.squeeze())\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "    # find True Positive indices\n",
    "    idxs = []\n",
    "    for i in range(width):\n",
    "        if pred[0][i] == y[0][i] and y[0][i] == 1:\n",
    "            idxs.append(i)\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    explanation = explainer(x.squeeze(), edge)\n",
    "    #explanation.visualize_feature_importance(top_k=10)\n",
    "    \n",
    "    node_mask = explanation.node_mask\n",
    "\n",
    "    if node_mask[idxs, :].shape != (0, 1950):\n",
    "        node_mask = torch.mean(node_mask[idxs, :], dim=0)\n",
    "        node_mask = np.array(node_mask.cpu())\n",
    "        mean_1 += node_mask\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "print('done interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950,)\n",
      "[7.06409774e-01 1.33410343e+00 1.33968231e+00 ... 1.33289106e-11\n",
      " 1.33981869e-02 8.71319438e-04]\n"
     ]
    }
   ],
   "source": [
    "mean = mean_1 / cnt\n",
    "print(mean.shape)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(mean), 'mean_GraphZSAGEConv_v5_lin_Saliency.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
